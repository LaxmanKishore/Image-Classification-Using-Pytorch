{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n",
      "Epoch 1/7.. Train loss: 4.626.. Valid loss: 4.577.. Valid accuracy: 0.028\n",
      "Epoch 1/7.. Train loss: 4.544.. Valid loss: 4.531.. Valid accuracy: 0.025\n",
      "Epoch 1/7.. Train loss: 4.485.. Valid loss: 4.494.. Valid accuracy: 0.056\n",
      "Epoch 1/7.. Train loss: 4.554.. Valid loss: 4.487.. Valid accuracy: 0.056\n",
      "Epoch 1/7.. Train loss: 4.523.. Valid loss: 4.479.. Valid accuracy: 0.055\n",
      "Epoch 1/7.. Train loss: 4.489.. Valid loss: 4.442.. Valid accuracy: 0.026\n",
      "Epoch 1/7.. Train loss: 4.483.. Valid loss: 4.416.. Valid accuracy: 0.025\n",
      "Epoch 1/7.. Train loss: 4.434.. Valid loss: 4.374.. Valid accuracy: 0.055\n",
      "Epoch 1/7.. Train loss: 4.384.. Valid loss: 4.318.. Valid accuracy: 0.050\n",
      "Epoch 1/7.. Train loss: 4.286.. Valid loss: 4.236.. Valid accuracy: 0.049\n",
      "Epoch 1/7.. Train loss: 4.260.. Valid loss: 4.137.. Valid accuracy: 0.095\n",
      "Epoch 1/7.. Train loss: 4.185.. Valid loss: 4.028.. Valid accuracy: 0.105\n",
      "Epoch 1/7.. Train loss: 4.153.. Valid loss: 3.935.. Valid accuracy: 0.115\n",
      "Epoch 1/7.. Train loss: 4.066.. Valid loss: 3.830.. Valid accuracy: 0.117\n",
      "Epoch 1/7.. Train loss: 4.006.. Valid loss: 3.716.. Valid accuracy: 0.142\n",
      "Epoch 1/7.. Train loss: 3.873.. Valid loss: 3.617.. Valid accuracy: 0.139\n",
      "Epoch 1/7.. Train loss: 3.745.. Valid loss: 3.440.. Valid accuracy: 0.194\n",
      "Epoch 1/7.. Train loss: 3.770.. Valid loss: 3.395.. Valid accuracy: 0.222\n",
      "Epoch 1/7.. Train loss: 3.653.. Valid loss: 3.148.. Valid accuracy: 0.242\n",
      "Epoch 1/7.. Train loss: 3.349.. Valid loss: 3.140.. Valid accuracy: 0.237\n",
      "Epoch 2/7.. Train loss: 3.563.. Valid loss: 3.058.. Valid accuracy: 0.231\n",
      "Epoch 2/7.. Train loss: 3.376.. Valid loss: 3.010.. Valid accuracy: 0.265\n",
      "Epoch 2/7.. Train loss: 3.398.. Valid loss: 2.970.. Valid accuracy: 0.284\n",
      "Epoch 2/7.. Train loss: 3.215.. Valid loss: 2.785.. Valid accuracy: 0.350\n",
      "Epoch 2/7.. Train loss: 3.064.. Valid loss: 2.645.. Valid accuracy: 0.342\n",
      "Epoch 2/7.. Train loss: 3.055.. Valid loss: 2.601.. Valid accuracy: 0.331\n",
      "Epoch 2/7.. Train loss: 2.893.. Valid loss: 2.446.. Valid accuracy: 0.362\n",
      "Epoch 2/7.. Train loss: 2.856.. Valid loss: 2.402.. Valid accuracy: 0.380\n",
      "Epoch 2/7.. Train loss: 2.745.. Valid loss: 2.346.. Valid accuracy: 0.373\n",
      "Epoch 2/7.. Train loss: 2.774.. Valid loss: 2.253.. Valid accuracy: 0.410\n",
      "Epoch 2/7.. Train loss: 2.809.. Valid loss: 2.181.. Valid accuracy: 0.426\n",
      "Epoch 2/7.. Train loss: 2.666.. Valid loss: 2.164.. Valid accuracy: 0.400\n",
      "Epoch 2/7.. Train loss: 2.592.. Valid loss: 2.157.. Valid accuracy: 0.419\n",
      "Epoch 2/7.. Train loss: 2.579.. Valid loss: 2.094.. Valid accuracy: 0.441\n",
      "Epoch 2/7.. Train loss: 2.479.. Valid loss: 1.965.. Valid accuracy: 0.475\n",
      "Epoch 2/7.. Train loss: 2.472.. Valid loss: 1.962.. Valid accuracy: 0.485\n",
      "Epoch 2/7.. Train loss: 2.432.. Valid loss: 1.831.. Valid accuracy: 0.490\n",
      "Epoch 2/7.. Train loss: 2.451.. Valid loss: 1.889.. Valid accuracy: 0.490\n",
      "Epoch 2/7.. Train loss: 2.274.. Valid loss: 1.911.. Valid accuracy: 0.473\n",
      "Epoch 2/7.. Train loss: 2.405.. Valid loss: 1.717.. Valid accuracy: 0.545\n",
      "Epoch 2/7.. Train loss: 2.341.. Valid loss: 1.741.. Valid accuracy: 0.539\n",
      "Epoch 3/7.. Train loss: 2.309.. Valid loss: 1.924.. Valid accuracy: 0.448\n",
      "Epoch 3/7.. Train loss: 2.250.. Valid loss: 1.747.. Valid accuracy: 0.542\n",
      "Epoch 3/7.. Train loss: 2.354.. Valid loss: 1.712.. Valid accuracy: 0.536\n",
      "Epoch 3/7.. Train loss: 2.162.. Valid loss: 1.681.. Valid accuracy: 0.529\n",
      "Epoch 3/7.. Train loss: 2.165.. Valid loss: 1.546.. Valid accuracy: 0.578\n",
      "Epoch 3/7.. Train loss: 2.093.. Valid loss: 1.494.. Valid accuracy: 0.582\n",
      "Epoch 3/7.. Train loss: 2.027.. Valid loss: 1.493.. Valid accuracy: 0.588\n",
      "Epoch 3/7.. Train loss: 1.941.. Valid loss: 1.490.. Valid accuracy: 0.578\n",
      "Epoch 3/7.. Train loss: 2.221.. Valid loss: 1.448.. Valid accuracy: 0.599\n",
      "Epoch 3/7.. Train loss: 1.928.. Valid loss: 1.409.. Valid accuracy: 0.631\n",
      "Epoch 3/7.. Train loss: 2.027.. Valid loss: 1.474.. Valid accuracy: 0.584\n",
      "Epoch 3/7.. Train loss: 1.793.. Valid loss: 1.353.. Valid accuracy: 0.620\n",
      "Epoch 3/7.. Train loss: 2.006.. Valid loss: 1.325.. Valid accuracy: 0.644\n",
      "Epoch 3/7.. Train loss: 1.790.. Valid loss: 1.442.. Valid accuracy: 0.605\n",
      "Epoch 3/7.. Train loss: 2.002.. Valid loss: 1.330.. Valid accuracy: 0.618\n",
      "Epoch 3/7.. Train loss: 2.012.. Valid loss: 1.319.. Valid accuracy: 0.615\n",
      "Epoch 3/7.. Train loss: 1.835.. Valid loss: 1.266.. Valid accuracy: 0.652\n",
      "Epoch 3/7.. Train loss: 1.786.. Valid loss: 1.255.. Valid accuracy: 0.629\n",
      "Epoch 3/7.. Train loss: 1.866.. Valid loss: 1.277.. Valid accuracy: 0.625\n",
      "Epoch 3/7.. Train loss: 1.757.. Valid loss: 1.163.. Valid accuracy: 0.654\n",
      "Epoch 4/7.. Train loss: 1.868.. Valid loss: 1.187.. Valid accuracy: 0.680\n",
      "Epoch 4/7.. Train loss: 1.957.. Valid loss: 1.123.. Valid accuracy: 0.700\n",
      "Epoch 4/7.. Train loss: 1.728.. Valid loss: 1.134.. Valid accuracy: 0.678\n",
      "Epoch 4/7.. Train loss: 1.705.. Valid loss: 1.166.. Valid accuracy: 0.655\n",
      "Epoch 4/7.. Train loss: 1.618.. Valid loss: 1.107.. Valid accuracy: 0.684\n"
     ]
    }
   ],
   "source": [
    "# Imports here\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# *********************************************************Load the data***************************************************\n",
    "\n",
    "# data_paths \n",
    "data_dir = 'flowers'\n",
    "\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "\n",
    "\n",
    "# Data transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.RandomRotation(25),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])]),\n",
    "    'valid' : transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])]),\n",
    "    'test' : transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "}\n",
    "train_transforms = data_transforms['train']\n",
    "valid_transforms = data_transforms['valid']\n",
    "test_transforms =data_transforms['test']\n",
    "\n",
    "\n",
    "\n",
    "# Image Datasets\n",
    "image_datasets = {\n",
    "    'train' : datasets.ImageFolder(train_dir,transform=train_transforms),\n",
    "    'valid': datasets.ImageFolder(valid_dir,transform=valid_transforms),\n",
    "    'test' : datasets.ImageFolder(test_dir,transform=test_transforms)\n",
    "}\n",
    "train_dataset =image_datasets['train']\n",
    "valid_dataset =image_datasets['valid']\n",
    "test_dataset = image_datasets['test']\n",
    "\n",
    "\n",
    "\n",
    "# Data loaders \n",
    "data_loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(valid_dataset,batch_size=64),\n",
    "    'test' : torch.utils.data.DataLoader(test_dataset,batch_size=64)    \n",
    "}\n",
    "train_loader = data_loaders['train']\n",
    "valid_loader = data_loaders['valid']\n",
    "test_loader  = data_loaders['test']\n",
    "\n",
    "\n",
    "# *********************************************************Label Mapping***************************************************\n",
    "\n",
    "import json\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "print(\"training done\")\n",
    "\n",
    "\n",
    "# ******************************************Building and training the classifier*******************************************\n",
    "\n",
    "\n",
    "# ******************************************Building the classifier*******************************************\n",
    "# selecting \"densenet121\" as the pretrained model as the number of inputs is less 1024 but contain more hidden layers\n",
    "\n",
    "n_inputs = 1024 ## will get from the pretrained model\n",
    "n_outputs = 102 # as defined in the dataset total of 102 different flower types\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters(): # Freeze parameters so we don't backprop through them\n",
    "    param.requires_grad = False\n",
    "\n",
    "    \n",
    "# Defining our classifier for the pretrained model\n",
    "Classifier = nn.Sequential(nn.Linear(n_inputs,800),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.3),\n",
    "                                 nn.Linear(800,512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.4),\n",
    "                                 nn.Linear(512, 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.3),\n",
    "                                 nn.Linear(256, n_outputs),\n",
    "                                  nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.classifier = Classifier\n",
    "\n",
    "criterion = nn.NLLLoss() # Defining the loss as NLLLoss\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001) \n",
    "\n",
    "\n",
    "# Move input and label tensors to the GPU and also the model\n",
    "for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "model = model.to(device)\n",
    "\n",
    "print(\"training done\")\n",
    "\n",
    "# ******************************************Training the classifier*******************************************\n",
    "\n",
    "\n",
    "def train_the_model(model,criterion,optimizer,train_loader,valid_loader,epochs):\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    print_every = 5\n",
    "    train_losses, valid_losses = [], []\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            steps += 1\n",
    "            # Move input and label tensors to the default device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logps = model.forward(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                valid_loss = 0\n",
    "                accuracy = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in valid_loader:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        logps = model.forward(inputs)\n",
    "                        batch_loss = criterion(logps, labels)\n",
    "\n",
    "                        valid_loss += batch_loss.item()\n",
    "\n",
    "                        # Calculate accuracy\n",
    "                        ps = torch.exp(logps)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                train_losses.append(running_loss/print_every)\n",
    "                valid_losses.append(valid_loss/len(valid_loader))                    \n",
    "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                      f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                      f\"Valid loss: {valid_loss/len(valid_loader):.3f}.. \"\n",
    "                      f\"Valid accuracy: {accuracy/len(valid_loader):.3f}\")\n",
    "                running_loss = 0\n",
    "                model.train()\n",
    "\n",
    "    return model\n",
    "epochs = 7\n",
    "model = train_the_model(model,criterion,optimizer,train_loader,valid_loader,epochs)\n",
    "\n",
    "  \n",
    "# To view the performance in a graph\n",
    "# plt.plot(train_losses, label='Training loss')\n",
    "# plt.plot(valid_losses, label='Validation loss')\n",
    "# plt.legend(frameon=False)\n",
    "\n",
    "\n",
    "# ******************************************Testing the classifier*******************************************\n",
    "\n",
    "def testing_model(model,test_loader,criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logps = model.forward(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "\n",
    "            test_loss += batch_loss.item()\n",
    "            # Calculate accuracy\n",
    "            ps = torch.exp(logps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "    print(f\"Test loss: {test_loss/len(test_loader):.3f}.. \"\n",
    "                f\"Test accuracy: {100*(accuracy/len(test_loader)):.3f}\")\n",
    "    return test_loss/len(test_loader),100*(accuracy/len(test_loader))\n",
    "\n",
    "\n",
    "test_loss,test_accuracy = testing_model(model,test_loader,criterion)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ******************************************Saving the Checkpoint*******************************************\n",
    "\n",
    "\n",
    "model.class_to_idx = train_dataset.class_to_idx\n",
    "class_names = train_dataset.classes\n",
    "saved_model = {'input_size':n_inputs,\n",
    "               'output_size':n_outputs,\n",
    "               'epochs': 5,\n",
    "               'batch_size':64,\n",
    "               'model' : models.densenet121(pretrained=True),\n",
    "               'Classifier': Classifier,\n",
    "               'optimizer' : optimizer.state_dict(),\n",
    "               'state_dict':model.state_dict(),\n",
    "               'class_to_idx': model.class_to_idx,\n",
    "               'class_names' : class_names\n",
    "}\n",
    "torch.save(saved_model,\"saved_model.pth\")\n",
    "\n",
    "\n",
    "print(\"model trained Saved Successfully with  accuracy\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************************************Loading the Checkpoint*******************************************\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "loaded_model = torch.load('saved_model.pth')\n",
    "def load_model(file_path,map_location='cpu'):\n",
    "    \n",
    "    loaded_model = torch.load(file_path)\n",
    "    model1 = loaded_model['model']\n",
    "    model1.classifier = loaded_model['Classifier']\n",
    "    model1.load_state_dict(loaded_model['state_dict'],strict=False)\n",
    "    model1.class_to_idx = loaded_model['class_to_idx']\n",
    "    optimizer = loaded_model['optimizer']\n",
    "    epochs = loaded_model['epochs']\n",
    "    class_names = loaded_model['class_names']\n",
    "\n",
    "    for param in model1.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return model1,loaded_model['class_to_idx'],class_names\n",
    "\n",
    "model,class_to_idx,class_names = load_model('saved_model.pth')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#******************************************Processing the input image*******************************************\n",
    "\n",
    "def process_image(image):\n",
    "    \n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    transform = transforms.Compose([\n",
    "                 transforms.Resize(256),\n",
    "                 transforms.CenterCrop(224),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                      [0.229, 0.224, 0.225])\n",
    "                 ])\n",
    "\n",
    "    return transform(image)\n",
    "\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# ******************************************Predicting the image*******************************************\n",
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    model.eval()\n",
    "    image = Image.open(image_path)\n",
    "    img =process_image(image)\n",
    "    \n",
    "    img = np.expand_dims(img,0) # 2D to 1D\n",
    "    \n",
    "    img = torch.from_numpy(img)\n",
    "    \n",
    "    inputs = Variable(img).to(device)\n",
    "    log_ps = model.forward(inputs)\n",
    "    \n",
    "    ps = F.softmax(log_ps,dim=1)\n",
    "    topk = ps.cpu().topk(topk)\n",
    "    \n",
    "    return (i.data.numpy().squeeze().tolist() for i in topk)\n",
    "    \n",
    "    \n",
    "image_path = \"assets/Capture_test_flower.JPG\"\n",
    "probs, classes = predict(image_path, model)\n",
    "print(classes)\n",
    "print(probs)\n",
    "\n",
    "#***************************Getting top 5 predicted names for the flower*****************************\n",
    "flower_names= [cat_to_name[class_names[i]] for i in classes]\n",
    "print(flower_names)\n",
    "\n",
    "\n",
    "#******************************************Sanity Checking*******************************************\n",
    "\n",
    "def view_classify(image_path,probs,classes,mapping):\n",
    "    # to view image and get predicted class\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    fig,(ax1,ax2) = plt.subplots(figsize=(8,10),ncols=1,nrows=2)\n",
    "    flower_name = flower_names[0]\n",
    "    ax1.set_title(flower_name)\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_pos = np.arange(len(probs))\n",
    "    ax2.barh(y_pos,probs,align='center')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(flower_names)\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_title('Class Probability')\n",
    "    \n",
    "view_classify(image_path,probs,classes,cat_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
